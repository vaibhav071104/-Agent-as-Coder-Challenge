pandas>=2.0.0
pdfplumber>=0.7.0
requests>=2.28.0
pytest>=7.0.0


#!/usr/bin/env python3
"""
Enhanced Bank Parser Agent - CLASSIFICATION FIXED
Supports both Groq + Gemini APIs with fallback parser
"""

import os
import re
import argparse
import importlib
import importlib.util
import pandas as pd
import pdfplumber
import requests
import py_compile
from typing import Tuple, Optional

# =========================
# ðŸ”‘ API KEYS (Load safely)
# =========================
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "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")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyDebXz1Hj3tyTZ5X8lHdTTjqzDYqRrvzSA")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models"

# =========================
# ðŸš€ API CALL HELPERS
# =========================
def groq_generate(prompt: str, model: str = "gemma2-9b-it") -> Optional[str]:
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are a Python expert. "
                    "CRITICAL: Each transaction must have EXACTLY ONE amount - "
                    "either Debit OR Credit, NEVER both. Always use pdfplumber.open()."
                )
            },
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1,
        "max_tokens": 2000,
        "stream": False
    }
    try:
        resp = requests.post(GROQ_API_URL, headers=headers, json=data, timeout=60)
        if resp.status_code == 200:
            return resp.json()["choices"][0]["message"]["content"]
        return None
    except Exception as e:
        print(f"âŒ Groq error: {e}")
        return None


def gemini_generate(prompt: str, model: str = "gemini-2.0-flash") -> Optional[str]:
    headers = {
        "Content-Type": "application/json",
        "X-goog-api-key": GEMINI_API_KEY
    }
    data = {
        "contents": [{"parts": [{"text": prompt}]}]
    }
    try:
        resp = requests.post(
            f"{GEMINI_API_URL}/{model}:generateContent",
            headers=headers, json=data, timeout=60
        )
        if resp.status_code == 200:
            candidates = resp.json().get("candidates", [])
            if candidates:
                return candidates[0]["content"]["parts"][0]["text"]
        else:
            print(f"âŒ Gemini API error {resp.status_code}: {resp.text}")
        return None
    except Exception as e:
        print(f"âŒ Gemini error: {e}")
        return None


# =========================
# ðŸ› ï¸ Utility
# =========================
def is_valid_python(file_path: str) -> bool:
    """Check if Python file has valid syntax."""
    try:
        py_compile.compile(file_path, doraise=True)
        return True
    except py_compile.PyCompileError:
        return False


# =========================
# ðŸ¤– Main Agent
# =========================
class BankParserAgent:
    def __init__(self, max_attempts: int = 3):
        self.max_attempts = max_attempts
        print("ðŸ¤– BankParserAgent CLASSIFICATION-FIXED initialized")

    def plan(self, target_bank: str) -> dict:
        return {
            "target": target_bank,
            "pdf_path": f"data/{target_bank}/icic_sample.pdf",
            "csv_path": f"data/{target_bank}/result.csv",
            "output_path": f"custom_parsers/{target_bank}_parser.py",
            "strategy": "CLASSIFICATION-FIXED generation"
        }

    def observe_pdf_structure(self, pdf_path: str) -> str:
        print("ðŸ” OBSERVE: Analyzing PDF structure")
        try:
            with pdfplumber.open(pdf_path) as pdf:
                sample_text = ""
                for page in pdf.pages[:2]:
                    text = page.extract_text()
                    if text:
                        sample_text += text + "\n"
                lines = sample_text.split("\n")
                tx_lines = [
                    line.strip() for line in lines
                    if line.strip() and re.match(r"^\d{2}-\d{2}-\d{4}", line.strip())
                ]
                print(f"âœ… OBSERVE: Found {len(tx_lines[:8])} sample transactions")
                return "\n".join(tx_lines[:8])
        except Exception as e:
            print(f"âŒ OBSERVE error: {e}")
            return ""

    def generate_parser_code(self, pdf_structure: str, csv_path: str, attempt: int = 1) -> str:
        print(f"ðŸ¤– GENERATE: Creating parser (attempt {attempt})")
        expected_df = pd.read_csv(csv_path)
        target_rows = len(expected_df)

        prompt = f"""Write Python function `parse(pdf_path: str) -> pd.DataFrame` for ICICI bank statements.
Rules:
- Each transaction has EXACTLY ONE amount: Debit OR Credit (never both).
- credit_keywords = {{"salary","credit","interest","deposit","cash","cheque","neft"}}
- If keyword in desc â†’ Credit else Debit.
- Columns: Date, Description, Debit Amt, Credit Amt, Balance
- Extract {target_rows} rows
- Always use: `with pdfplumber.open(pdf_path) as pdf:`
- No `from pdfplumber import open_pdf`
- Return COMPLETE Python code only (no markdown).

Sample lines:
{pdf_structure}
"""

        # Try Groq first, then Gemini
        providers = [
            ("Groq", "gemma2-9b-it", groq_generate),
            ("Groq", "llama-3.1-8b-instant", groq_generate),
            ("Gemini", "gemini-2.0-flash", gemini_generate)
        ]

        for provider, model, func in providers:
            print(f"  ðŸ”„ Trying {provider} model: {model}")
            code = func(prompt, model=model)
            if code and "def parse" in code:
                print(f"  âœ… {provider} {model} generated code")
                return self._clean_code(code)

        print("  ðŸ›¡ï¸ Using fallback parser")
        return self.get_guaranteed_parser()

    def _clean_code(self, code: str) -> str:
        """
        Clean and sanitize LLM-generated parser code so it compiles correctly.
        """

        # 1. Remove markdown fences and language tags
        code = re.sub(r"```.*?python", "", code, flags=re.DOTALL | re.IGNORECASE)
        code = re.sub(r"```", "", code)

        # 2. Fix wrong pdfplumber imports
        code = code.replace("from pdfplumber import open_pdf", "import pdfplumber")
        code = code.replace("from pdfplumber import PDF", "import pdfplumber")

        # 3. Ensure pandas and re imports
        if "import pandas" not in code:
            code = "import pandas as pd\n" + code
        if "import re" not in code:
            code = "import re\n" + code

        # 4. Force function signature
        code = re.sub(
            r"def\s+parse\s*\(.*\):",
            "def parse(pdf_path: str) -> pd.DataFrame:",
            code,
            count=1
        )

        # 5. Ensure skip_words and credit_keywords exist INSIDE parse()
        if "def parse" in code:
            code = re.sub(
                r"(def parse\(.*?:)",
                r"\1\n    skip_words = {\"date\", \"description\", \"debit amt\", \"credit amt\", \"balance\"}\n"
                r"    credit_keywords = {\"salary\", \"credit\", \"interest\", \"deposit\", \"cash\", \"cheque\", \"neft\", \"received\", \"refund\"}",
                code,
                count=1,
            )

        # 6. Remove trailing junk like explanations or printouts
        lines = code.splitlines()
        clean_lines = []
        for line in lines:
            clean_lines.append(line)
            if re.match(r"^\s*return\s+df\s*", line):
                break
        code = "\n".join(clean_lines)

        return code.strip()

    def get_guaranteed_parser(self) -> str:
        return '''import pandas as pd
import pdfplumber
import re

def parse(pdf_path: str) -> pd.DataFrame:
    transactions = []
    skip_words = {"date","description","debit amt","credit amt","balance"}
    credit_keywords = {"salary","credit","interest","deposit","cash","cheque","neft"}
    seen = set()
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if not text: continue
            for line in text.split("\\n"):
                line=line.strip()
                if not line or any(sw in line.lower() for sw in skip_words): continue
                if not re.match(r"^\\d{2}-\\d{2}-\\d{4}", line): continue
                parts=line.split()
                if len(parts)<4: continue
                date, desc, amt_str, bal_str = parts[0], " ".join(parts[1:-2]), parts[-2], parts[-1]
                try:
                    amt=float(amt_str); bal=float(bal_str)
                except: continue
                key=(date,desc,round(bal,2))
                if key in seen: continue
                seen.add(key)
                is_credit = any(k in desc.lower() for k in credit_keywords)
                debit_amt, credit_amt = ("",str(amt)) if is_credit else (str(amt),"")
                transactions.append({"Date":date,"Description":desc,"Debit Amt":debit_amt,"Credit Amt":credit_amt,"Balance":bal})
    df=pd.DataFrame(transactions,columns=["Date","Description","Debit Amt","Credit Amt","Balance"])
    for c in ["Debit Amt","Credit Amt"]:
        df[c]=df[c].apply(lambda x:str(x) if x!="" else "")
    print(f"PERFECT CLASSIFICATION: {len(df)} transactions")
    return df
'''

    def test_parser(self, parser_code: str, pdf_path: str, csv_path: str, output_path: str) -> Tuple[bool, str]:
        print("ðŸ§ª TEST: Validating parser")
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, "w") as f:
            f.write(parser_code)

        if not is_valid_python(output_path):
            return False, "Syntax error in generated parser"

        # Load dynamically
        spec = importlib.util.spec_from_file_location("test_parser", output_path)
        if spec is None or spec.loader is None:
            return False, "Failed to load module spec"
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        df = module.parse(pdf_path)
        expected = pd.read_csv(csv_path)

        if list(df.columns) != ["Date","Description","Debit Amt","Credit Amt","Balance"]:
            return False, "Schema mismatch"

        both = sum(
            1 for _,r in df.iterrows()
            if str(r["Debit Amt"]).strip() and str(r["Credit Amt"]).strip()
        )
        if both > 0:
            return False, f"Classification error: {both} rows have BOTH amounts"

        if len(df)==len(expected):
            return True, f"âœ… PERFECT CLASSIFICATION! {len(df)}/{len(expected)} (100%)"
        elif len(df)>=len(expected)*0.95:
            acc=(len(df)/len(expected))*100
            return True, f"âœ… EXCELLENT CLASSIFICATION! {len(df)}/{len(expected)} ({acc:.1f}%)"
        else:
            return False, f"Low accuracy: {len(df)}/{len(expected)}"

    def run(self, target_bank: str) -> bool:
        print(f"\nðŸš€ Agent running for {target_bank.upper()}")
        plan = self.plan(target_bank)
        if not os.path.exists(plan["pdf_path"]) or not os.path.exists(plan["csv_path"]):
            print("âŒ Missing files")
            return False
        structure = self.observe_pdf_structure(plan["pdf_path"])
        for attempt in range(1,self.max_attempts+1):
            print(f"\nðŸ”„ Attempt {attempt}/{self.max_attempts}")
            code=self.generate_parser_code(structure, plan["csv_path"], attempt)
            success,msg=self.test_parser(code, plan["pdf_path"], plan["csv_path"], plan["output_path"])
            if success:
                print(f"\nðŸŽ‰ SUCCESS: {msg}")
                return True
            else:
                print(f"âŒ Attempt {attempt}: {msg}")
        print("\nðŸ›¡ï¸ FALLBACK mode")
        code=self.get_guaranteed_parser()
        success,msg=self.test_parser(code, plan["pdf_path"], plan["csv_path"], plan["output_path"])
        print(f"ðŸ“ˆ FALLBACK: {msg}")
        return success


def main():
    parser=argparse.ArgumentParser(description="CLASSIFICATION-FIXED Agent")
    parser.add_argument("--target",required=True,help="Bank (e.g. icici)")
    args=parser.parse_args()
    agent=BankParserAgent()
    success=agent.run(args.target)
    if success:
        print(f"\nâœ… Parser ready: custom_parsers/{args.target}_parser.py")
    else:
        print("\nâŒ Failed")


if __name__=="__main__":
    main()





import pandas as pd
import pdfplumber
import re


def parse(pdf_path: str) -> pd.DataFrame:
    transactions = []
    skip_words = {"date", "description", "debit amt", "credit amt", "balance"}
    credit_keywords = {
        "salary",
        "credit",
        "interest",
        "deposit",
        "cash",
        "cheque",
        "neft",
    }
    seen = set()
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if not text:
                continue
            for line in text.split("\n"):
                line = line.strip()
                if not line or any(sw in line.lower() for sw in skip_words):
                    continue
                if not re.match(r"^\d{2}-\d{2}-\d{4}", line):
                    continue
                parts = line.split()
                if len(parts) < 4:
                    continue
                date, desc, amt_str, bal_str = (
                    parts[0],
                    " ".join(parts[1:-2]),
                    parts[-2],
                    parts[-1],
                )
                try:
                    amt = float(amt_str)
                    bal = float(bal_str)
                except:
                    continue
                key = (date, desc, round(bal, 2))
                if key in seen:
                    continue
                seen.add(key)
                is_credit = any(k in desc.lower() for k in credit_keywords)
                debit_amt, credit_amt = ("", str(amt)) if is_credit else (str(amt), "")
                transactions.append(
                    {
                        "Date": date,
                        "Description": desc,
                        "Debit Amt": debit_amt,
                        "Credit Amt": credit_amt,
                        "Balance": bal,
                    }
                )
    df = pd.DataFrame(
        transactions,
        columns=["Date", "Description", "Debit Amt", "Credit Amt", "Balance"],
    )
    for c in ["Debit Amt", "Credit Amt"]:
        df[c] = df[c].apply(lambda x: str(x) if x != "" else "")
    print(f"PERFECT CLASSIFICATION: {len(df)} transactions")
    return df
